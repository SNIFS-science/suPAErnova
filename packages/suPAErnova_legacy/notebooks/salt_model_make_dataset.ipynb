{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1GPcDXzglxA"
   },
   "source": [
    "lightcurve investigations using sncosmo \n",
    "https://sncosmo.readthedocs.io\n",
    "\n",
    "Helpful links on supernova literature and data from Sam Dixon are here:\n",
    "https://docs.google.com/document/d/1pbr42wX-s6-RKVnN9TONPhm4cjnrCQCv-uqfB67LPeY/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OylEoz4ZgUIq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import sncosmo\n",
    "#%matplotlib inline\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "data_dir = '/global/homes/g/gstein/src/snfdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in original data from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv containing SN names and SALT fit parameters\n",
    "meta = pd.read_csv(os.path.join(data_dir, 'meta.csv'), index_col=0)\n",
    "\n",
    "# A seperate file contains additional SALT fit parameters (dphase), so match with meta dataframe and append column\n",
    "df_dt = np.genfromtxt(os.path.join(data_dir, 'IDR_eTmax.txt'), dtype=None, names=('name', '_', 'days'))\n",
    "deltat_name = df_dt['name'].astype(str)\n",
    "deltat_days = df_dt['days']\n",
    "\n",
    "ind = np.where(deltat_name == meta['sn'].iloc[0])[0][0]\n",
    "\n",
    "meta_deltat = [deltat_days[np.where(deltat_name == meta['sn'].iloc[i])[0][0]] for i in range(meta['sn'].shape[0])]\n",
    "meta_sn = [deltat_name[np.where(deltat_name == meta['sn'].iloc[i])[0][0]] for i in range(meta['sn'].shape[0])]\n",
    "\n",
    "meta['dphase'] = meta_deltat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get mask for bad spectra/wavelength range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_mask = np.genfromtxt(\n",
    "    \"../data/mask_info_wmin_wmax.txt\",\n",
    "    delimiter=' ',\n",
    "    dtype=('<U32', '<U32', int, float, float),\n",
    "    names=('sn_name',\n",
    "           'spectra_id',\n",
    "           'flag',\n",
    "           'wavelength_min',\n",
    "           'wavelength_max',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check SN look as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_spectra(sn_name):\n",
    "    \"\"\"Gets the wavelength, phase, and flux of all spectra corresponding\n",
    "    to a given SN.\n",
    "    \"\"\"\n",
    "    sn_meta = meta[meta.sn==sn_name]\n",
    "    waves, fluxes, phases, sigma, spec_id = [], [], [], [], []\n",
    "    \n",
    "    for i, spec_info in sn_meta.iterrows():\n",
    "        data = pd.read_csv(os.path.join(data_dir, spec_info.path))\n",
    "        spec_id.append( str(os.path.splitext(os.path.basename(spec_info.path))[0][-14:]) )\n",
    "        waves.append(data.wave)\n",
    "        fluxes.append(data.flux)\n",
    "        sigma.append(data.sigma)\n",
    "        phases.append(spec_info.phase)\n",
    "    return np.array(waves), np.array(fluxes), np.array(phases), np.array(sigma), spec_id\n",
    "\n",
    "def plot_sn_spectra(sn_name):\n",
    "    \"\"\"Plots all given spectra of a supernova\"\"\"\n",
    "    waves, fluxes, phases, sigmas, spec_ids = get_all_spectra(sn_name)\n",
    "    norm = mpl.colors.Normalize(min(phases), max(phases))\n",
    "    cmap = mpl.cm.ScalarMappable(norm=norm, cmap=plt.cm.viridis)\n",
    "    cmap.set_array([])\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for wave, flux, phase in zip(waves, fluxes, phases):\n",
    "        plt.plot(wave, flux, color=cmap.to_rgba(phase))\n",
    "    plt.colorbar(cmap, label='Phase')\n",
    "    plt.xlabel('Rest-frame wavelength ($\\AA$)')\n",
    "    plt.ylabel('Normalized flux')\n",
    "    plt.title(sn_name)\n",
    "\n",
    "sn_name = np.random.choice(meta.sn.unique())\n",
    "plot_sn_spectra(sn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec_id in spec_ids:\n",
    "    \n",
    "    try:\n",
    "        ind = np.where(spectra_mask['spectra_id']==spec_id)[0][0]\n",
    "        # \n",
    "        mask_wavelength_min = spectra_mask['wavelength_min'][ind]\n",
    "        mask_wavelength_max = spectra_mask['wavelength_max'][ind]\n",
    "        \n",
    "    except:\n",
    "        mask_wavelength_min, mask_wavelength_max = 3298.68, 9701.23 # use whole spectra\n",
    "kh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile from individual text files into easy to use arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspectra = 0\n",
    "nwaves   = 0\n",
    "nsn = 0\n",
    "for sn_name in meta.sn.unique()[:1]:\n",
    "#     print(sn_name)\n",
    "    waves, fluxes, phases, sigmas, spec_ids = get_all_spectra(sn_name)\n",
    "    nwaves = waves.shape[-1]\n",
    "\n",
    "nspectra = meta.shape[0]\n",
    "nsn = meta.sn.unique().shape[0]\n",
    "\n",
    "print('total number of sn = ', nsn)  \n",
    "print('total number of spectra = ', nspectra)\n",
    "\n",
    "# desired parameters to keep\n",
    "params = ['dphase', 'z', 'x0', 'x1', 'c', 'MB', 'hubble_resid']\n",
    "nparams = len(params)\n",
    "\n",
    "#+1 for unique identifying as first, \n",
    "# +1 for number of phases from sn, \n",
    "# +1 for phase as 3rd param\n",
    "param_labels = ['ID', 'Nspectra_ID', 'phase'] + params\n",
    "\n",
    "\n",
    "data = {}\n",
    "O\n",
    "sn_names = []\n",
    "spectra_ids = []\n",
    "\n",
    "ispectra_prev = 0\n",
    "ispectra      = 0\n",
    "\n",
    "sn_meta = meta.drop_duplicates(subset='sn')\n",
    "for i, sn_name in enumerate(meta.sn.unique()):\n",
    "\n",
    "    # get sn spectra\n",
    "    waves, fluxes, phases, sigmas, spec_ids = get_all_spectra(sn_name)\n",
    "    \n",
    "    nspectra = len(phases)\n",
    "    ispectra += nspectra\n",
    "    \n",
    "    # get sn parameters\n",
    "    for j in range(nparams):\n",
    "        data['params'][ispectra_prev:ispectra, j+3] = sn_meta[params[j]][i]\n",
    "\n",
    "    sn_names += [sn_name] * nspectra\n",
    "    spectra_ids += spec_ids\n",
    "    \n",
    "    data['params'][ispectra_prev:ispectra, 0] = i\n",
    "    data['params'][ispectra_prev:ispectra, 1] = nspectra\n",
    "    data['params'][ispectra_prev:ispectra, 2] = phases\n",
    "    \n",
    "    data['spectra'][ispectra_prev:ispectra,:] = fluxes\n",
    "    data['sigma'][ispectra_prev:ispectra,:]  = sigmas\n",
    "    \n",
    "    # get mask for part of spectra\n",
    "    for j, spec_id in enumerate(spec_ids):\n",
    "        try:\n",
    "            ind = np.where(spectra_mask['spectra_id']==spec_id)[0][0]\n",
    "            data['wavelength_mask'][ispectra_prev+j, 0] = spectra_mask['wavelength_min'][ind]\n",
    "            data['wavelength_mask'][ispectra_prev+j, 1] = spectra_mask['wavelength_max'][ind]\n",
    "\n",
    "        except:\n",
    "            data['wavelength_mask'][ispectra_prev+j, 0], data['wavelength_mask'][ispectra_prev+j, 1] = 3298.68, 9701.23 # use whole spectra\n",
    "        \n",
    "    ispectra_prev += len(phases)\n",
    "  \n",
    "data['names'] = np.array(sn_names)\n",
    "data['spectra_ids'] = np.array(spectra_ids)\n",
    "data['wavelengths'] = waves[0,:]\n",
    "for i, param in enumerate(param_labels):\n",
    "    data[param] = data['params'][:,i]\n",
    "\n",
    "data['ID'] = data['ID'].astype(int)\n",
    "data['Nspectra_ID'] = data['Nspectra_ID'].astype(int)\n",
    "\n",
    "data['redshift'] = data.pop('z') # rename redshift field\n",
    "\n",
    "data.pop('params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/snf_data.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/snf_data.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get spectra from SALT2 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1573686360735,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "MYIJh-NN_-k6",
    "outputId": "5a4ecb37-11d8-49da-caf5-405f8fe18618"
   },
   "outputs": [],
   "source": [
    "# Redshift to dictance functions\n",
    "# assuming Wmap9 paramaters as done in SALT\n",
    "\n",
    "# from astropy.cosmology import FlatLambdaCDM \n",
    "# cosmo = FlatLambdaCDM(H0=73., Om0=0.28)\n",
    "from astropy.cosmology import WMAP7 as cosmo\n",
    "print(cosmo.luminosity_distance(0.05))\n",
    "\n",
    "\n",
    "# create supernova model\n",
    "# in SALT2 model, 𝐹(𝑡,𝜆)=𝑥0(𝑀0(𝑡,𝜆)+𝑥1𝑀1(𝑡,𝜆))×10^−0.4𝐶𝐿(𝜆)𝑐\n",
    "\n",
    "snmodel = sncosmo.SALT2Source(modeldir='/global/homes/g/gstein/.astropy/cache/sncosmo/models/salt2/salt2-4/')\n",
    "print('parameters are: ', snmodel.param_names)\n",
    "\n",
    "def get_flux(wavelength, tobs=0, z=0., x0=1., x1=0.0, c=0.0, t0=0., zref=0.05, verbose=False):\n",
    "    '''given observer-frame phase and set of wavelengths, returns SALT2 SN spectra in ergs/s/cm^2/Angstrom at a given reference frame redshift\n",
    "    \n",
    "    salt2 model is in observer-frame, so need to change from observer frame to zref observation through luminosity distance\n",
    "\n",
    "    from sncosmo docs:\n",
    "    Note that in some sources phase=0 might be at explosion while others might be at max: the definition of phase is arbitrary. \n",
    "    However, observed time is always related to phase via time = t0 + phase * (1 + z)\n",
    "    '''\n",
    "\n",
    "\n",
    "    # use SALT2SOurce module, not generic one set to SALT2\n",
    "    snmodel = sncosmo.SALT2Source(modeldir='/global/homes/g/gstein/.astropy/cache/sncosmo/models/salt2/salt2-4/')\n",
    "    snmodel.set(x0=x0, x1=x1, c=c)\n",
    "\n",
    "    # info on snmodel\n",
    "    if verbose:\n",
    "        print(snmodel.minwave(), snmodel.maxwave())\n",
    "        print(snmodel.param_names)\n",
    "        print(snmodel.parameters)\n",
    "\n",
    "    return snmodel.flux(phase=tobs, wave=wavelength) * (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) * 1e15 \n",
    "\n",
    "wavelengths = np.linspace(3000,8000,1000)\n",
    "# try function\n",
    "flux = get_flux(wavelengths, x0=1., x1=0., c=0., z=0.1, verbose=True)\n",
    "plt.plot(flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut data outside of desired range\n",
    "print(\"Number of unique SN \", np.unique(data['ID']).shape[0])\n",
    "print(\"n spectra before cut = \", data['spectra'].shape[0])\n",
    "\n",
    "print(\"Number spectra in SN min\", np.min(np.bincount(data['ID'])))\n",
    "print(\"Number spectra in SN max\", np.max(np.bincount(data['ID'])))\n",
    "\n",
    "# cut data outside of wanted ranges\n",
    "tmin = -10\n",
    "tmax = 40\n",
    "dm = (tmin < data['phase']) & (tmax > data['phase'])\n",
    "print(dm)\n",
    "for k, v in data.items():\n",
    "    print(k)\n",
    "    if v.shape[0] == dm.shape[0]:\n",
    "        data[k] = v[dm]\n",
    "    \n",
    "print(\"n spectra after cut = \", data['spectra'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SALT spectra for each\n",
    "zref = 0.05\n",
    "\n",
    "data['spectra_salt'] = np.zeros(data['spectra'].shape)\n",
    "\n",
    "for i in range(data['spectra_salt'].shape[0]):\n",
    "    if i%100 == 0: print('done {0}'.format(i))\n",
    "    data['spectra_salt'][i] = get_flux(data['wavelengths'], tobs=data['phase'][i], z=data['redshift'][i], x0=data['x0'][i], x1=data['x1'][i], c=data['c'][i]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/snf_data_wSALT.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, inds = np.unique(data['ID'], return_index=True)\n",
    "u, inds\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = np.load(\"data/train_data_kfold0.npy\", allow_pickle=True).item()\n",
    "data_old = np.load(\"data/model_outputs/train_data_kfold0.npy\", allow_pickle=True).item()\n",
    "\n",
    "for k in data_old.keys():\n",
    "    if k in data_new.keys():\n",
    "        dm = data_new[k] != data_old[k]\n",
    "        not_eq = np.any(dm)\n",
    "        print(k, not_eq)\n",
    "        if not_eq:\n",
    "            print(data_old[k][dm], data_new[k][dm])\n",
    "            \n",
    "data_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make salt grid\n",
    "# nt = 64\n",
    "# times = np.linspace(-10, 40, nt)\n",
    "# # flux = get_flux(wavelengths, x0=1, x1=0, c=0, verbose=True)\n",
    "\n",
    "# flux = np.zeros((nt, data['wavelengths'].shape[0]), dtype=np.float32)\n",
    "# plt.figure()\n",
    "# # flux = get_flux(wavelengths, tobs=times, z=0, x0=1, x1=0, c=0, verbose=False)\n",
    "# # print(data['wavelengths'])\n",
    "# print(cond_params.min(0), cond_params.max(0))\n",
    "# for i in range(nt):\n",
    "#     print(i)\n",
    "#     flux[i] = get_flux(data['wavelengths'], tobs=times[i], z=0.05, x0=1, x1=1, c=0.0, verbose=False)\n",
    "\n",
    "#     plt.plot(flux[i])\n",
    "\n",
    "# np.savez('salt_spec_64times_x1.npz', flux=flux, wavelengths=data['wavelengths'], tobs=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(np.unique(IDs).shape)\n",
    "# Match salt spectra with real data\n",
    "nplt   = 4 #220\n",
    "nstart = 0 #220 - 5 #nplt\n",
    "# plt.figure(figsize=(15,10))\n",
    "norm = 0.\n",
    "\n",
    "# salt params\n",
    "cs = 'k'\n",
    "lss = '-'\n",
    "\n",
    "# sn \n",
    "csn = 'C1'\n",
    "\n",
    "zmin = cond_params[:, 1].min()\n",
    "zmax = cond_params[:, 1].max()\n",
    "\n",
    "nx = 2\n",
    "ny = math.ceil(nplt/nx)\n",
    "fig, axs = plt.subplots(ny, nx, figsize=(nx*3,ny*2))\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "amplitude_offsets = np.zeros(nplt)\n",
    "for i, idi in enumerate(np.unique(IDs)[nstart:nstart+nplt]): #cond_params.shape[0]): \n",
    "\n",
    "    dm = (IDs == idi)\n",
    "\n",
    "    spec = data['spectra'][dm]\n",
    "    sigma_x = data['sigma'][dm]\n",
    "    cond = cond_params[dm]\n",
    "    salt = salt_params[dm]\n",
    "\n",
    "    print(salt[0], cond[0])\n",
    "    nobs = spec.shape[0]\n",
    "    print('ID={:d}, Number of observations = {:d}'.format(idi, nobs))\n",
    "\n",
    "    amp_offset = []\n",
    "    for n in range(nobs):\n",
    "\n",
    "        spec_salt_ = get_flux(data['wavelengths'], tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "#         spec_salt_ = get_flux(data['wavelengths'], tobs=cond[n,0], z=cond[n,1], x0=1., x1=salt[n,1], c=salt[n,2]) \n",
    "\n",
    "#         plt.plot(data['wavelengths'], spec_salt_, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "#         plt.plot(data['wavelengths'], spec[n], ls=\"-\", c='k', lw=2, zorder=1)\n",
    "\n",
    "#         axs[i].plot(data['wavelengths'], spec_salt_/spec[n], c=cm.jet(n/nobs), lw=1, ls=lss, zorder=1)\n",
    "        axs[i].plot(data['wavelengths'], spec_salt_/spec[n], c=cm.jet( (cond[n,1] - zmin)/(zmax-zmin)), lw=1, ls=lss, zorder=1)\n",
    "\n",
    "        axs[i].axhline(1, color='k', ls='--', label='z={:.3f}'.format(cond[n,1]))\n",
    "\n",
    "        amp_offset.append(np.mean(  (spec_salt_/spec[n])[-100:]  ))\n",
    "    \n",
    "    axs[i].text(data['wavelengths'][data['wavelengths'].shape[0]//2], 1.95, 'z={:.3f}'.format(cond[0,1]), ha='center', va='top', fontsize=14)\n",
    "    \n",
    "    amplitude_offsets[i] = np.mean(amp_offset)\n",
    "    axs[i].set_xlim(3.25e3, 7e3)\n",
    "    axs[i].set_ylim(0.5, 2.)\n",
    "\n",
    "    if i // ny == ny-1:\n",
    "        axs[i].set_xlabel('Wavelength')\n",
    "    else:\n",
    "        axs[i].get_xaxis().set_visible(False)\n",
    "\n",
    "#     if i % nx ==0:\n",
    "    \n",
    "#         axs[i].set_ylabel('$Flux_{salt2} / Flux_{data}$')\n",
    "    if i % nx != 0:\n",
    "        axs[i].get_yaxis().set_visible(False)\n",
    "\n",
    "    axs[i].set_yscale('log')\n",
    "    \n",
    "# plt.savefig('all_spectra.pdf', bbox_inches='tight')\n",
    "plt.figure()\n",
    "plt.hist(amplitude_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xbins = np.linspace(0.5, 2, 25)\n",
    "\n",
    "plt.hist(amplitude_offsets, bins=xbins)\n",
    "\n",
    "plt.title('Mean amplitude offset for 220 SN', fontsize=14)\n",
    "plt.xlabel(r'$\\frac{1}{N^{SN}_{spec}}\\sum_{spec}\\frac{F^{SN}_{salt}(\\lambda > 6180)} {F^{SN}_{data}(\\lambda > 6180)}$')\n",
    "plt.ylabel('$N_{SN}$')\n",
    "data['wavelengths'][-100]\n",
    "\n",
    "plt.savefig('spectra_amplitude_offset_hist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(salt_params[:, 0])\n",
    "plt.scatter(cond_params[:, 1], salt_params[:, 0], c=np.arange(salt_params[:, 0].shape[0]))\n",
    "plt.yscale('log')\n",
    "plt.ylim(0.00001, 3)\n",
    "# plt.scatter(salt_params[:,0][:len(amplitude_offsets)], amplitude_offsets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "z = cond_params[:, 1]\n",
    "A = (salt_params[:, 0] / ( (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) )).value\n",
    "print(salt_params[:, 0])\n",
    "plt.figure()\n",
    "plt.plot(cond_params[:, 1], A, 'o')\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "# plt.ylim(0.00001, 10000)\n",
    "# plt.scatter(salt_params[:,0][:len(amplitude_offsets)], amplitude_offsets)\n",
    "\n",
    "\n",
    "bins = np.logspace(-1,1,25)\n",
    "bins = np.linspace(0.1,10,25)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(A/salt_params[:, 0], bins=bins)\n",
    "# plt.xscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmins = [0.0, 0.02, 0.04, 0.05]\n",
    "zmin1 = 0.02\n",
    "zmin2 = 0.02\n",
    "\n",
    "redshift = cond_params[:,1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(redshift, bins=25)\n",
    "\n",
    "for i, zmin in enumerate(zmins):\n",
    "    plt.axvline(zmin, color='C{:d}'.format(i%10), label=\"N_SN(z > {:.2f}) = {:d}\".format(zmin, np.sum(np.unique(redshift) > zmin) ))\n",
    "    \n",
    "plt.xlabel('redshift')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the encoder will be conditioned to both X and c, where X=flux spectra and c=conditional paramaters [t, redshift, ...]\n",
    "# similarly, the decoder will take as input z and c, where z are the latent variables \n",
    "\n",
    "np.savez('../data/snf_data_wSALT.npz', \n",
    "         wavelengths       = data['wavelengths'],\n",
    "         spectra           = data['spectra'],\n",
    "         spectra_salt      = data['spectra_salt'],\n",
    "         sigma             = data['sigma'],\n",
    "         spectra_IDs       = IDs,\n",
    "         names             = names,\n",
    "         cond_params       = cond_params,\n",
    "         cond_params_label = cond_params_label,\n",
    "         salt_params       = salt_params,\n",
    "         salt_params_label = salt_params_label  \n",
    "        )\n",
    "\n",
    "# ['wavelengths', 'spectra', 'spectra_salt', 'spectra_sigma', 'spectra_IDs', 'cond_params', 'cond_params_label', 'salt_params', 'salt_params_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Look at dust laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_file = np.load('../data/sn_spectra_arrays_wsigma.npz')\n",
    "print(sn_file.files)\n",
    "sn_spectra       = sn_file['sn_array'].astype('float32')\n",
    "sigma_spectra    = sn_file['sigma_array'].astype('float32')\n",
    "\n",
    "wavelengths      = sn_file['wavelengths']#.astype('float32')\n",
    "param_array      = sn_file['param_array'].astype('float32')\n",
    "param_labels     = sn_file['param_labels']\n",
    "IDs              = param_array[:,0].astype('int')\n",
    "\n",
    "\n",
    "Rv = 3.1\n",
    "# SALT2\n",
    "snmodel = sncosmo.SALT2Source(modeldir='/global/homes/g/gstein/.astropy/cache/sncosmo/models/salt2/salt2-4/')\n",
    "CL = snmodel.colorlaw(wavelengths)\n",
    "# plt.plot(wavelengths, 10**(-0.4*CL*0.1))\n",
    "plt.plot(wavelengths, CL)\n",
    "\n",
    "\n",
    "# Fitzpatrick 99\n",
    "dR = 0.01\n",
    "Rvi = 3.1\n",
    "Rvs = [Rvi-dR/2, Rvi, Rvi+dR/2]\n",
    "\n",
    "ext = np.zeros((wavelengths.shape[0], len(Rvs)))\n",
    "# get derivative\n",
    "for irv, Rv in enumerate(Rvs):\n",
    "    plt.figure()\n",
    "    dust_model = sncosmo.F99Dust(r_v=Rv)\n",
    "\n",
    "    Fmult_i = np.ones_like(wavelengths)\n",
    "\n",
    "    # plt.plot(wavelengths, Fmult_i)\n",
    "\n",
    "    nsave = 10\n",
    "    extinction_array = np.zeros((nsave))\n",
    "    ebvs = [1.] #np.linspace(-0.1, 0.1, nsave)\n",
    "    for iebv, ebv in enumerate(ebvs):\n",
    "        dust_model.set(ebv=ebv)\n",
    "\n",
    "        Fmult_f = dust_model.propagate(wavelengths, Fmult_i)\n",
    "\n",
    "        CL_F99 = np.log10(Fmult_f)/-0.4/ebv\n",
    "        plt.plot(wavelengths, CL_F99)\n",
    "\n",
    "    ext[:, irv] = CL_F99\n",
    "   \n",
    "CL_F99_prime = (ext[:,-1] - ext[:, 0])/dR\n",
    "\n",
    "Fmult_i = np.ones_like(wavelengths)\n",
    "\n",
    "# plt.plot(wavelengths, Fmult_i)\n",
    "\n",
    "\n",
    "dust_model = sncosmo.F99Dust(r_v=3.1)\n",
    "dust_model.set(ebv=1.)\n",
    "Fmult_f = dust_model.propagate(wavelengths, Fmult_i)\n",
    "CL_F99 = np.log10(Fmult_f)/-0.4/ebv\n",
    "\n",
    "np.savetxt('../data/F99_colorlaw.txt', np.c_[wavelengths, CL_F99, CL_F99_prime])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ext)\n",
    "diff = (ext[:,-1] - ext[:, 0])/dR\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(diff)\n",
    "# plt.plot(ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Luminosity distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at magnitudes\n",
    "# from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "\n",
    "cosmo = FlatLambdaCDM(H0=73, Om0=0.28, Tcmb0=2.725)\n",
    "\n",
    "z = np.linspace(0.001,0.4,1000)\n",
    "dl_z = cosmo.luminosity_distance(z).value \n",
    "d_z = cosmo.comoving_distance(z).value\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(z, d_z)\n",
    "plt.plot(z, dl_z)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(z, 5*np.log10(dl_z*1e6/10))\n",
    "plt.plot(z, 5*np.log10(d_z*1e6/10))\n",
    "\n",
    "# np.savetxt('dl_of_z.txt', np.c_[z, dl_z.value])\n",
    "\n",
    "\n",
    "zmin = 0.0\n",
    "zmax = 0.2\n",
    "zref = 0.05\n",
    "nz   = 1000\n",
    "\n",
    "z_interp_vals   = np.linspace(zmin, zmax, nz)\n",
    "dl_interp_vals =  (cosmo.luminosity_distance(z_interp_vals)/cosmo.luminosity_distance(zref)).value\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(z_interp_vals, dl_interp_vals)\n",
    "plt.yscale('log')\n",
    "\n",
    "np.savetxt('../data/luminosity_distance.txt', np.c_[z_interp_vals.astype(np.float32), dl_interp_vals.astype(np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_to_F(L, z, inv=False):\n",
    "    # I am calling the restframe flux F_rest as \"L\", and observed flux F_obs F\n",
    "    # from the IDR notes we have Fobs = Frest * (1+zref)/(1+z_helio) * (d_L(z_ref, z_ref)/d_L(z_helio, z_CMB))^2 * 1/1e15\n",
    "    # assuming z_CMB = z_helio for now, and not using constants 1e15 or (1+zref)\n",
    "    dl2_ratio = tfp.math.interp_regular_1d_grid(x=z, x_ref_min=z_interp_vals[0], x_ref_max=z_interp_vals[-1], y_ref=dl2_interp_vals, fill_value_below=0.)\n",
    "\n",
    "    if not inv:\n",
    "        return L / (dl2_ratio) #/ (1+z)\n",
    "    else:\n",
    "        return L * (dl2_ratio) #* (1+z)\n",
    "\n",
    "L_to_F(1., 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift x0 relative to z\n",
    "zref = 0.05\n",
    "# z, x0 = np.loadtxt('x0_vs_z.txt', unpack=True)\n",
    "# # print(x0, z)\n",
    "# x0_z_fac = (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) \n",
    "# dl_z     = cosmo.luminosity_distance(z)\n",
    "\n",
    "# print(z, x0, x0_z_fac)\n",
    "# plt.figure()\n",
    "# plt.plot(z, x0, '.')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(z, np.log10(x0), '.')\n",
    "# # plt.yscale('log')\n",
    "    \n",
    "# plt.figure()\n",
    "# # plt.plot(z, x0_z_fac '.')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(z, x0*x0_z_fac, '.')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(z, x0/x0_z_fac, '.')\n",
    "# plt.yscale('symlog')\n",
    "\n",
    "# np.savetxt('x0_vs_z_with_x0z_fac.txt', np.c_[z, x0, x0_z_fac.value, dl_z.value])\n",
    "\n",
    "\n",
    "\n",
    "# # look at colorlaw\n",
    "# sn_file = np.load('../data/sn_spectra_arrays_wsigma.npz')\n",
    "\n",
    "# wavelengths      = sn_file['wavelengths']\n",
    "\n",
    "# snmodel = sncosmo.SALT2Source(modeldir='/global/homes/g/gstein/.astropy/cache/sncosmo/models/salt2/salt2-4/')\n",
    "\n",
    "# CL = snmodel.colorlaw(wavelengths)\n",
    "# np.savetxt('SALT2_colorlaw.txt', np.c_[wavelengths, CL])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(CL)\n",
    "\n",
    "# cs = np.linspace(-1, 1, 5)\n",
    "# plt.figure()\n",
    "# for i in range(len(cs)):\n",
    "#     plt.plot(wavelengths, 10**(-0.4*CL*cs[i]))\n",
    "\n",
    "# source = sncosmo.get_source('SALT2')\n",
    "# snmodel = sncosmo.Model(source=source)\n",
    "# snmodel = sncosmo.SALT2model(source='SALT2')\n",
    "# snmodel = sncosmo.Model(source='SALT2')\n",
    "\n",
    "print('paramaters are: ', snmodel.param_names)\n",
    "\n",
    "# def get_colorlaw(wavelength):\n",
    "#   '''returns SALT2 colorlaw as a function of wavelength'''\n",
    "#    # default for SALT2 in snscosmo are:\n",
    "#    # x0 = 1.0, x1 = 0.0, c  = 0.0\n",
    "\n",
    "# #       snmodel.set_source_peakabsmag(-19.0, 'bessellb', 'ab')\n",
    "\n",
    "# #       return snmodel.flux(time=tobs, wave=wavelength) * (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z) * 1e15\n",
    "\n",
    "# #       return snmodel.flux(time=tobs, wave=wavelength) * 1e15 \n",
    "\n",
    "\n",
    "\n",
    "# get_colorlaw(wavelengths)\n",
    "\n",
    "# help(snmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3051,
     "status": "ok",
     "timestamp": 1573693222538,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "_hjsdryAg8ou",
    "outputId": "f68be7db-af13-48a7-cef3-e20484840708"
   },
   "outputs": [],
   "source": [
    "if not gpu:\n",
    "    # Visualize how spectra change as functions of SALT paramaters\n",
    "\n",
    "    x1 = 0.;   x1min=-2; x1max=2 # [-3, 3] flat distribution\n",
    "    c  = 0.2;  cmin=-0.1;  cmax=0.5  # [-0.1, 0.5] flat distribution\n",
    "    z  = 0.05; zmin=0.01;   zmax=0.1  # [0.3, 0.8] flat distribution\n",
    "    t0 = 0;    tmin=-10;   tmax=20   # [-10, 20] flat distribution\n",
    "\n",
    "    # wavelengths to get spectra at\n",
    "    lmin = 3750\n",
    "    lmax = 9000\n",
    "    nlbin = 288\n",
    "    l = np.linspace(lmin,lmax, nlbin)\n",
    "\n",
    "    ntbin = 10\n",
    "    t = [-10,0,20] #np.linspace(tmin,tmax,ntbin)\n",
    "\n",
    "    nsamp = 5 # number of samples along feature dimension\n",
    "    x1samp = np.linspace(x1min, x1max, nsamp)\n",
    "    csamp  = np.linspace(cmin, cmax, nsamp)\n",
    "    zsamp  = np.linspace(zmin, zmax, nsamp)\n",
    "\n",
    "    # get fiducial spectra of SN\n",
    "    F    = get_flux(l, t, z=z, x1=x1, c=c) # get spectra at peak\n",
    "    norm = 1.e-13 #np.mean(F, axis=0)\n",
    "\n",
    "    # normalize fluxes and time\n",
    "    # F /= norm\n",
    "    #t = t/(tmax-tmin)\n",
    "\n",
    "    # Plot spectra\n",
    "    cmap = cm.coolwarm\n",
    "    colors = cmap(np.linspace(0,1,nsamp))\n",
    "\n",
    "    ncols = len(t)\n",
    "    nrows = 2\n",
    "    fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(16,8), sharex=True, sharey=True)\n",
    "    plt.subplots_adjust(hspace=0.05, wspace=0.0)\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    for i in range(len(t)):\n",
    "\n",
    "      for j in range(nsamp):\n",
    "\n",
    "#         # vary redshift\n",
    "#         F = get_flux(l, tobs=t[i], z=zsamp[j], x0=0.02, x1=x1, c=c)#/norm\n",
    "#         ax[0,i].plot(l, F, color=colors[j], label=\"z = %.2f\"%zsamp[j])\n",
    "\n",
    "        # vary x1\n",
    "        F = get_flux(l, tobs=t[i], z=z, x0=0.02, x1=x1samp[j], c=c)#/norm\n",
    "        ax[0,i].plot(l, F, color=colors[j], label=\"x$_1$ = %.2f\"%x1samp[j])\n",
    "\n",
    "        # vary c\n",
    "        F = get_flux(l, tobs=t[i], z=z, x0=0.02, x1=x1, c=csamp[j])#/norm\n",
    "        ax[1,i].plot(l, F, color=colors[j], label=\"c = %.2f\"%csamp[j])\n",
    "\n",
    "\n",
    "      ax[0,i].set_title('Time = %.2f'%t[i], fontsize=14)\n",
    "\n",
    "    ax[0,1].set_zorder(10)\n",
    "    ax[1,1].set_zorder(10)\n",
    "\n",
    "    ax[0,1].legend(fontsize=14, ncol=nsamp, loc='upper center', frameon=False, handletextpad=0.25, handlelength=1.5, columnspacing=1., labelspacing=0.25)\n",
    "    ax[1,1].legend(fontsize=14, ncol=nsamp, loc='upper center', frameon=False, handletextpad=0.25, handlelength=1.5, columnspacing=1., labelspacing=0.25)\n",
    "\n",
    "    # ax[0,0].set_ylim(-1,5)\n",
    "    ax[-1,0].set_xlabel('wavelength [$\\AA$]')\n",
    "    ax[-1,1].set_xlabel('wavelength [$\\AA$]')\n",
    "\n",
    "    ax[0,0].set_ylabel('Flux')\n",
    "    ax[1,0].set_ylabel('Flux')\n",
    "\n",
    "    # plt.savefig('sn_spectra_varied.pdf')#, bbox_inches='tight')\n",
    "\n",
    "    #files.download('sn_spectra_varied.pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2139,
     "status": "ok",
     "timestamp": 1573693222541,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "9W_oiIRpgf-c",
    "outputId": "44fd78f7-08e4-4ee3-d6b8-9ee95ddf77b2"
   },
   "outputs": [],
   "source": [
    "# Create fake dataset for training \n",
    "if not gpu: \n",
    "    from scipy import interpolate\n",
    "    import math\n",
    "\n",
    "    # redshift = False # True to de-redshift data to restframe, False to not\n",
    "    redshift = True\n",
    "    grid     = False # sample paramaters on uniform grid (True), or randomly (False)\n",
    "\n",
    "    x1min=-3; x1max=3 # [-3, 3] flat distribution\n",
    "    cmin=-0.1;  cmax=0.5  # [-0.1, 0.5] flat distribution\n",
    "    zmin=0.03;   zmax=0.15  # [0.3, 0.8] flat distribution\n",
    "    tmin=-15;   tmax=15   # [-10, 20] flat distribution\n",
    "\n",
    "    zmid  = (zmax+zmin)/2\n",
    "    tmid  = (tmax+tmin)/2\n",
    "    x1mid = (x1max+x1min)/2\n",
    "    cmid  = (cmax+cmin)/2\n",
    "\n",
    "    # wavelengths to get spectra at\n",
    "    wavelength_min = 3750\n",
    "    wavelength_max = 9000 #11500 # lmin, lmax chosen to be within model wavelength range bewteen z=[0.3, 0.8]\n",
    "    nbin_wavelength = 256 #lmax-lmin+1\n",
    "    wavelengths = np.linspace(wavelength_min,wavelength_max,nbin_wavelength)\n",
    "\n",
    "     # number of samples along feature dimensions\n",
    "    if grid:\n",
    "      nsamp_t  = 10\n",
    "      nsamp_x1 = 10\n",
    "      nsamp_c  = 10\n",
    "      nsamp_z  = 10\n",
    "\n",
    "      nsamp_tot = nsamp_t*nsamp_x1*nsamp_c*nsamp_z\n",
    "\n",
    "      np.random.seed(13579)\n",
    "      tsamp  = np.linspace(tmin,  tmax,  nsamp_t) #*0+tmid\n",
    "      zsamp  = np.linspace(zmin,  zmax,  nsamp_z) #*0+zmid\n",
    "\n",
    "      x1samp = np.linspace(x1min, x1max, nsamp_x1)\n",
    "      csamp  = np.linspace(cmin,  cmax,  nsamp_c)\n",
    "\n",
    "      nsamples = int(ntbin*nsamp**3)\n",
    "      print(\"total number of individual samples = \", nsamp_tot)\n",
    "      # get fiducial spectra of SN\n",
    "\n",
    "      Z, T, X1, C = np.meshgrid(zsamp, tsamp, x1samp, csamp) # c varies fastest, then x1, then z, then t\n",
    "\n",
    "      cond_params = np.c_[T.flatten(), Z.flatten()]\n",
    "      salt_params = np.c_[X1.flatten(), C.flatten()]\n",
    "\n",
    "    else:\n",
    "      # random paramaters uniformly distributed\n",
    "      nsamp_tot   = 100\n",
    "      train_dim = 2\n",
    "\n",
    "      np.random.seed(13579)\n",
    "      cond_params = np.random.uniform(0,1, size=(nsamp_tot,2))\n",
    "      salt_params = np.random.uniform(0,1, size=(nsamp_tot,2))\n",
    "\n",
    "      #transform paramaters to relevant ranges\n",
    "      cond_params[:,0] = cond_params[:,0]*(tmax-tmin) + tmin\n",
    "      cond_params[:,1] = cond_params[:,1]*(zmax-zmin) + zmin\n",
    "      salt_params[:,0] = salt_params[:,0]*(x1max-x1min) + x1min\n",
    "      salt_params[:,1] = salt_params[:,1]*(cmax-cmin) + cmin\n",
    "\n",
    "\n",
    "    # Print paramaters\n",
    "    # for i in range(nsamp_x1*nsamp_c*nsamp_z):\n",
    "    #   print(cond_params[i], salt_params[i])\n",
    "\n",
    "\n",
    "    sn_spectra = np.zeros((nsamp_tot, nbin_wavelength)) \n",
    "\n",
    "\n",
    "    # loop over paramaters, as sncosmo does not seem to support multiple paramater calls, only multiple time slices. But loop over time anyways for now as it is fast enough\n",
    "    for i in range(cond_params.shape[0]):\n",
    "      sn_spectra[i,:] = get_flux(wavelengths, tobs=cond_params[i,0], z=cond_params[i,1], x1=salt_params[i,0], c=salt_params[i,1]) # get spectra for all paramaters\n",
    "\n",
    "\n",
    "    # get de-redshifted spectra. Shift into frame of z=0, and apply Flux to Luminosity conversion\n",
    "    if redshift:\n",
    "      wavelength_min_dr = math.ceil(wavelength_min/(1+zmin)) # minimum wavelength at z=0\n",
    "      wavelength_max_dr = math.floor(wavelength_max/(1+zmax)) # maximim wavelength at z=0\n",
    "      nbin_wavelength_dr = wavelength_max_dr-wavelength_min_dr+1\n",
    "\n",
    "      print(\"min, max, wavelength available after de-redshifting\", wavelength_min_dr, wavelength_max_dr)\n",
    "\n",
    "      wavelengths_dr = np.linspace(wavelength_min_dr, wavelength_max_dr, nbin_wavelength_dr)\n",
    "      sn_spectra_dr = np.zeros((nsamp_tot, nbin_wavelength_dr)) \n",
    "\n",
    "      for i in range(cond_params.shape[0]):\n",
    "        zp1 = cond_params[i,1] + 1\n",
    "\n",
    "        # create 1D interpolation function to get de-redshifted spectra \n",
    "        # probably a smarter way to bin into de-redshifted wavelength bins, but good enough for now\n",
    "        f_dr = interpolate.interp1d(wavelengths/zp1, sn_spectra[i,:])# * (1+cond_params[i,1])) \n",
    "        # With the (1+z) factor the flux is no longer a function of redshift?\n",
    "        # but keeping it here for future\n",
    "\n",
    "        sn_spectra_dr[i,:] = f_dr(wavelengths_dr)\n",
    "\n",
    "\n",
    "      sn_spectra_norm = np.mean(sn_spectra_dr)#, axis=0)\n",
    "\n",
    "      sn_spectra_dr /= sn_spectra_norm\n",
    "      sn_spectra_dr  = sn_spectra_dr.astype('float32')\n",
    "\n",
    "    sn_spectra /= sn_spectra_norm\n",
    "\n",
    "    norm_cond = True #False\n",
    "    if norm_cond:\n",
    "      cond_params_mean   = np.mean(cond_params, axis=0)  \n",
    "      cond_params_maxmin = (np.max(cond_params, axis=0)-np.min(cond_params, axis=0)) \n",
    "      cond_params_maxmin[cond_params_maxmin==0.] = 1. # maxmin can be 0 if paramater is always 0, so set to 1\n",
    "\n",
    "      cond_params = (cond_params-cond_params_mean)/cond_params_maxmin\n",
    "      #cond_params = cond_params/cond_params_maxmin\n",
    "\n",
    "    sn_spectra  = sn_spectra.astype('float32')\n",
    "    cond_params = cond_params.astype('float32')\n",
    "    salt_params = salt_params.astype('float32')\n",
    "\n",
    "    print(\"data collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBR-L5pFrswY"
   },
   "outputs": [],
   "source": [
    "if not gpu:\n",
    "    from scipy import stats\n",
    "    # Downsample data\n",
    "    if redshift:\n",
    "      nbins_ds =  256  \n",
    "      sn_spectra_dr_b = np.zeros((nsamp_tot, nbins_ds))\n",
    "\n",
    "      wavelengths_dr_b_edge = np.linspace(wavelength_min_dr, wavelength_max_dr, nbins_ds+1) #linear bins\n",
    "      wavelengths_dr_b      = (wavelengths_dr_b_edge[1:]+wavelengths_dr_b_edge[:-1])/2 # linear bin center\n",
    "\n",
    "      sn_spectra_dr_b, wavelengths_b_edge, binnumber = stats.binned_statistic(wavelengths_dr, sn_spectra_dr, statistic='mean', bins=wavelengths_dr_b_edge)\n",
    "\n",
    "    # Add noise\n",
    "    # If noise is not added, and only one SALT variable (such as c) is varied, \n",
    "    # the latent space collapses, and the variational decoderdoes not work well at all  \n",
    "    noise = True\n",
    "    sigma_noise = 0.04\n",
    "\n",
    "    if noise:\n",
    "      sn_spectra += np.random.normal(loc=0, scale=sigma_noise, size=sn_spectra.shape)\n",
    "\n",
    "      sn_spectra_dr_b += np.random.normal(loc=0, scale=sigma_noise, size=sn_spectra_dr_b.shape)\n",
    "    sn_spectra_dr_b  = sn_spectra_dr_b.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1573693223434,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "3MbCfzDVZUBY",
    "outputId": "4430793d-32e3-4282-e4fc-79275742f24d"
   },
   "outputs": [],
   "source": [
    "# Load Real Data\n",
    "import glob\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "# Sam's data\n",
    "sn_file = np.load('../data/sn_spectra_arrays_wsigma.npz')\n",
    "print(sn_file.files)\n",
    "sn_spectra       = sn_file['sn_array'].astype('float32')\n",
    "sigma_spectra    = sn_file['sigma_array'].astype('float32')\n",
    "\n",
    "wavelengths      = sn_file['wavelengths']#.astype('float32')\n",
    "param_array      = sn_file['param_array'].astype('float32')\n",
    "param_labels     = sn_file['param_labels']\n",
    "IDs              = param_array[:,0].astype('int')\n",
    "\n",
    "print('parameters = ', param_labels)\n",
    "print(\"Number of unique SN \", np.unique(IDs).shape[0])\n",
    "print(\"n spectra before cut = \", sn_spectra.shape[0])\n",
    "\n",
    "print(\"Number spectra in SN min\", np.min(np.bincount(IDs)))\n",
    "print(\"Number spectra in SN max\", np.max(np.bincount(IDs)))\n",
    "\n",
    "cond_params = param_array[:,2:4]\n",
    "salt_params = param_array[:,4:]\n",
    "\n",
    "# salt_params[:,-1] *= 0.\n",
    "\n",
    "salt_params_label = param_labels[4:]\n",
    "cond_params_label = param_labels[2:4]\n",
    "print('salt, cond params = ', salt_params_label, cond_params_label)\n",
    "# cut data outside of wanted ranges\n",
    "tmin = -10\n",
    "tmax = 40\n",
    "dm = (cond_params[:,0] > tmin) & (cond_params[:,0] < tmax)\n",
    "sn_spectra = sn_spectra[dm]\n",
    "sigma_spectra = sigma_spectra[dm]\n",
    "cond_params = cond_params[dm]\n",
    "salt_params = salt_params[dm]\n",
    "\n",
    "IDs         = IDs[dm]\n",
    "print(\"n spectra after cut = \", sn_spectra.shape[0])\n",
    "\n",
    "redshift = False\n",
    "\n",
    "\n",
    "# # SUGAR data\n",
    "# sn_dir = '/global/cscratch1/sd/gstein/machine_learning/sn_project/data/SUGAR/sp/'\n",
    "# sn_train_f = sorted(glob.glob(sn_dir+'*training*'))\n",
    "# sn_test_f = sorted(glob.glob(sn_dir+'*testing*'))\n",
    "\n",
    "# f = sn_train_f[0]\n",
    "# print(f, f.split('_')[1].split)\n",
    "\n",
    "# ind = np.zeros()\n",
    "\n",
    "# sn_train_ind = [np.array(ntpath.basename(os.path.splitext(i)[0]).split('-')[2].split('_')).astype(int) for i in sn_train_f]\n",
    "# print(sn_train_ind[0:2])\n",
    "\n",
    "\n",
    "nsamp_tot = sn_spectra.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cond_params[:,0])\n",
    "plt.xlabel('phase')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cond_params[:,1], '.')\n",
    "plt.ylabel('z')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(np.unique(cond_params[:,1]))\n",
    "plt.xlabel('z')\n",
    "\n",
    "data_unique = np.unique(salt_params, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(data_unique[:,0], data_unique[:,-1])\n",
    "plt.xlabel('x0')\n",
    "plt.ylabel('c')\n",
    "plt.xlim(0, 0.1)\n",
    "\n",
    "for i, lab in enumerate(param_labels[4:]):\n",
    "    plt.figure()\n",
    "    datai = data_unique[:,i]\n",
    "    print('min max mean', lab, datai.min(), datai.max(), datai.mean())\n",
    "    plt.hist(datai)\n",
    "    plt.xlabel(lab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1573693228546,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "yncqnh3jB_lp",
    "outputId": "7649c5ce-0b08-46d6-d4a9-4b70836c9705"
   },
   "outputs": [],
   "source": [
    "# take a look at some random spectra\n",
    "nplt = 5\n",
    "pltevery = 1 #nsamp_tot//nplt\n",
    "cmap = cm.coolwarm\n",
    "colors = cmap(np.linspace(0,1,nplt))\n",
    "\n",
    "print(sigma_spectra.min(), sigma_spectra.max())\n",
    "print(sigma_spectra.min()**2, sigma_spectra.max()**2)\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(nrows=5, ncols=1, sharex=True, figsize=(14,16))\n",
    "for i in range(nplt):\n",
    "    ax1.plot(wavelengths, sn_spectra[i*pltevery], c=colors[i], label='t={:.2f}'.format(cond_params[i*pltevery,0]))\n",
    "    ax1.fill_between(wavelengths, sn_spectra[i*pltevery] - sigma_spectra[i*pltevery],  sn_spectra[i*pltevery] + sigma_spectra[i*pltevery]);\n",
    "    ax1.set_title(\"Observed, redshift =\"+str(cond_params[i*pltevery,1]))\n",
    "    ax1.set_ylabel('Restframe flux')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.semilogy(wavelengths, sigma_spectra[i*pltevery], c=colors[i]);\n",
    "    ax2.semilogy(wavelengths[200], sigma_spectra[0, 200], 'ko');\n",
    "\n",
    "    ax2.set_ylim(0, 0.02)\n",
    "    ax2.set_ylabel('Sigma')\n",
    "    \n",
    "      \n",
    "    ax3.semilogy(wavelengths, sigma_spectra[i*pltevery]**2, c=colors[i]);\n",
    "    ax3.set_ylabel('Sigma^2')\n",
    "          \n",
    "    ax4.semilogy(wavelengths, sn_spectra[i*pltevery]/sigma_spectra[i*pltevery], c=colors[i]);\n",
    "#     ax4.set_ylim(0, 0.02)\n",
    "    ax4.set_ylabel('Signal/noise')\n",
    "\n",
    "    ax5.semilogy(wavelengths, sn_spectra[i*pltevery]**2/sigma_spectra[i*pltevery]**2, c=colors[i]);\n",
    "#     ax5.set_ylim(0, 0.02)\n",
    "    ax5.set_xlabel(\"Wavelength [$\\AA$]\")\n",
    "    ax5.set_ylabel('Signal^2/noise^2')\n",
    "    \n",
    "    print(sigma_spectra.min(), sigma_spectra.max())\n",
    "if redshift:\n",
    "  plt.figure()\n",
    "  for i in range(nplt-1):\n",
    "    plt.plot(l_dr, sn_spectra_dr[i*pltevery], c=colors[i]);\n",
    "    plt.title(\"de-Redshifted\")\n",
    "    plt.xlabel(\"Wavelength [$\\AA$]\")\n",
    "\n",
    "  plt.figure()\n",
    "  for i in range(nplt-1):\n",
    "    plt.plot(l_dr_b, sn_spectra_dr_b[i*pltevery],c=colors[i]);\n",
    "    plt.title(\"de-Redshifted, Binned, and noise added\")\n",
    "    plt.xlabel(\"Wavelength $\\AA$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING DIFFERENT SNCOSMO IMPLEMENTATIONS\n",
    "def get_flux1(wavelength, tobs=0, z=0., x0=1., x1=0.0, c=0.0, t0=0., zref=0.05):\n",
    "\n",
    "    snmodel = sncosmo.Model(source='SALT2')\n",
    "#     print('paramaters are: ', snmodel.param_names)\n",
    "\n",
    "    snmodel.set(z=z, x0=x0, x1=x1, c=c, t0=t0)\n",
    "#         snmodel.set_source_peakabsmag(-19.0, 'bessellb', 'ab')\n",
    "  \n",
    "    return snmodel.flux(time=tobs*(1+z), wave=wavelength*(1+z)) * (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) * 1e15 \n",
    "\n",
    "def get_flux2(wavelength, tobs=0, z=0., x0=1., x1=0.0, c=0.0, t0=0., zref=0.05):\n",
    "\n",
    "    snmodel = sncosmo.Model(source='SALT2')\n",
    "#     print('paramaters are: ', snmodel.param_names)\n",
    "\n",
    "    snmodel.set(z=z, x0=x0, x1=x1, c=c, t0=t0)\n",
    "    snmodel.set_source_peakabsmag(-19.0, 'bessellb', 'ab')\n",
    "  \n",
    "    return snmodel.flux(time=tobs, wave=wavelength*(1+z)) #* (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) * 1e15 \n",
    "\n",
    "def get_flux3(wavelength, tobs=0, z=0., x0=1., x1=0.0, c=0.0, zref=0.05):\n",
    "\n",
    "    snmodel = sncosmo.SALT2Source(modeldir='/global/homes/g/gstein/.astropy/cache/sncosmo/models/salt2/salt2-4/')\n",
    "#     print('paramaters are: ', snmodel.param_names)\n",
    "\n",
    "    snmodel.set(x0=x0, x1=x1, c=c)\n",
    "#     snmodel.set_source_peakabsmag(-19.0, 'bessellb', 'ab')\n",
    "  \n",
    "    return snmodel.flux(phase=tobs, wave=wavelength) * (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) * 1e15 \n",
    "\n",
    "def get_flux4(wavelength, tobs=0, z=0., x0=1., x1=0.0, c=0.0, zref=0.05):\n",
    "\n",
    "    snmodel = sncosmo.SALT2Source(modeldir='/global/homes/g/gstein/.astropy/cache/sncosmo/models/salt2/salt2-4/')\n",
    "#     print('paramaters are: ', snmodel.param_names)\n",
    "\n",
    "    snmodel.set(x0=x0, x1=x1, c=c)\n",
    "    snmodel.set_peakmag(-19.0, 'bessellb', 'ab')\n",
    "  \n",
    "    return snmodel.flux(phase=tobs, wave=wavelength) #* (cosmo.luminosity_distance(z)/cosmo.luminosity_distance(zref))**2 * (1+z)/(1+zref) * 1e15 \n",
    "\n",
    "if not gpu:\n",
    "    # Match salt spectra with real data\n",
    "    nplt   = 1\n",
    "    nstart = 176\n",
    "    # plt.figure(figsize=(15,10))\n",
    "    norm = 0.\n",
    "    wavelength_norm = 51\n",
    "\n",
    "    # salt params\n",
    "    cs = 'k'\n",
    "    lss = '-'\n",
    "\n",
    "    # sn \n",
    "    csn = 'C1'\n",
    "\n",
    "    for i, idi in enumerate(np.unique(IDs)[nstart:nstart+nplt]): #cond_params.shape[0]): \n",
    "\n",
    "        dm = (IDs == idi)\n",
    "\n",
    "        spec = sn_spectra[dm]\n",
    "        sigma_x = sigma_spectra[dm]\n",
    "        cond = cond_params[dm]\n",
    "        salt = salt_params[dm]\n",
    "\n",
    "        nobs = spec.shape[0]\n",
    "        print('ID={:d}, Number of observations = {:d}'.format(idi, nobs))\n",
    "\n",
    "        plt.figure(figsize=(16,8))\n",
    "        for n in range(nobs):\n",
    "\n",
    "            salt_spectra1 = get_flux1(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "            salt_spectra2 = get_flux2(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "            salt_spectra3 = get_flux3(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "            salt_spectra4 = get_flux4(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "            print(salt_spectra1.shape, salt_spectra3.shape)\n",
    "\n",
    "            print(np.max(salt_spectra1/salt_spectra3 - 1))\n",
    "            print('3/4', np.max(np.abs(salt_spectra3/salt_spectra4)))\n",
    "\n",
    "#             print(np.max(np.abs(salt_spectra1-salt_spectra3)))\n",
    "\n",
    "#             plt.plot(wavelengths, salt_spectra1/salt_spectra2, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "#             plt.plot(wavelengths, salt_spectra1/salt_spectra3, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "\n",
    "            plt.plot(wavelengths, salt_spectra1, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "            plt.plot(wavelengths, spec[n], ls=\"-\", c='k', lw=2, zorder=1)\n",
    "\n",
    "\n",
    "        plt.xlim(3.25e3, 7e3)\n",
    "#         plt.yscale('log')\n",
    "        plt.xlabel('de-redshifted Wavelength')\n",
    "        plt.ylabel('Normalized Luminosity')\n",
    "        \n",
    "        plt.figure(figsize=(16,8))\n",
    "        for n in range(nobs):\n",
    "\n",
    "            salt_spectra1 = get_flux1(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "            salt_spectra2 = get_flux2(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "            salt_spectra3 = get_flux3(wavelengths, tobs=cond[n,0], z=cond[n,1], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "#             salt_spectra4 = get_flux4(wavelengths, tobs=cond[n,0], x0=salt[n,0], x1=salt[n,1], c=salt[n,2]) \n",
    "\n",
    "            plt.plot(wavelengths, salt_spectra3, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "            plt.plot(wavelengths, spec[n], ls=\"-\", c='k', lw=2, zorder=1)\n",
    "\n",
    "\n",
    "        plt.xlim(3.25e3, 7e3)\n",
    "#         plt.yscale('log')\n",
    "        plt.xlabel('de-redshifted Wavelength')\n",
    "        plt.ylabel('Normalized Luminosity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10727,
     "status": "ok",
     "timestamp": 1573693240034,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "HsC0hZmb__fz",
    "outputId": "8667164e-8cdf-4178-8138-a12e1af299dd"
   },
   "outputs": [],
   "source": [
    "CL = snmodel.colorlaw(wavelengths)\n",
    "\n",
    "\n",
    "if not gpu:\n",
    "    # Match salt spectra with real data\n",
    "    nplt   = 5\n",
    "    nstart = 0\n",
    "    # plt.figure(figsize=(15,10))\n",
    "    norm = 0.\n",
    "    wavelength_norm = 51\n",
    "\n",
    "    # salt params\n",
    "    cs = 'k'\n",
    "    lss = ':'#'-'\n",
    "\n",
    "    # sn \n",
    "    csn = 'C1'\n",
    "\n",
    "    for i, idi in enumerate(np.unique(IDs)[nstart:nstart+nplt]): #cond_params.shape[0]): \n",
    "\n",
    "        dm = (IDs == idi)\n",
    "\n",
    "        spec = sn_spectra[dm]\n",
    "        sigma_x = sigma_spectra[dm]\n",
    "        cond = cond_params[dm]\n",
    "        salt = salt_params[dm]\n",
    "\n",
    "        nobs = spec.shape[0]\n",
    "        print('ID={:d}, Number of observations = {:d}'.format(idi, nobs))\n",
    "\n",
    "        plt.figure(figsize=(16,8))\n",
    "        print(salt[0,2])\n",
    "        \n",
    "        Cli = 10**(-0.4*salt[0,2] * CL)\n",
    "        for n in range(nobs):\n",
    "\n",
    "            salt_spectra = get_flux(wavelengths, \n",
    "                                  tobs=cond[n,0], #/(1+cond[n,1]),  \n",
    "                                  z=cond[n,1], \n",
    "                                  x0=salt[n,0], \n",
    "                                  x1=salt[n,1], \n",
    "                                  c=salt[n,2]) \n",
    "\n",
    "#             salt_spectra /= Cli\n",
    "#             salt_spectra *= 1e15 \n",
    "\n",
    "            plt.plot(wavelengths, spec[n], ls=\"-\", c='k', lw=2, zorder=1)\n",
    "            plt.fill_between(wavelengths, spec[n]-sigma_x[n], spec[n]+sigma_x[n], color='k', lw=2, zorder=1, alpha=0.2)\n",
    "            plt.plot(wavelengths, salt_spectra, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "\n",
    "#             plt.plot(wavelengths, salt_spectra/spec[n], 'k')#c=cm.jet(n/nobs), lw=3, ls=lss, )\n",
    "#             print(cond[n])\n",
    "#             print('0', np.median(salt_spectra/spec[n]), np.mean(salt_spectra/spec[n]))\n",
    "\n",
    "        \n",
    "#             salt_spectra = get_flux(wavelengths, \n",
    "#                                   tobs=cond[n,0]*(1+cond[n,1])/(1.05), \n",
    "#                                   z=cond[n,1], \n",
    "#                                   x0=salt[n,0], \n",
    "#                                   x1=salt[n,1], \n",
    "#                                   c=salt[n,2]) \n",
    "            \n",
    "#             plt.plot(wavelengths, spec[n], ls=\"-\", c='k', lw=2, zorder=1)\n",
    "#             plt.fill_between(wavelengths, spec[n]-sigma_x[n], spec[n]+sigma_x[n], color='k', lw=2, zorder=1, alpha=0.2)\n",
    "#             plt.plot(wavelengths, salt_spectra, c=cm.jet(n/nobs), lw=3, ls=lss, zorder=1)\n",
    "\n",
    "#             plt.plot(wavelengths, salt_spectra/spec[n], 'r', alpha=0.5)#c=cm.jet(n/nobs), lw=3, ls=lss, )\n",
    "#             print('1', np.median(salt_spectra/spec[n]), np.mean(salt_spectra/spec[n]))\n",
    "    #         lab_o = None\n",
    "    #         lab_s = None\n",
    "            if n==0:\n",
    "                lab_o = 'Observed'\n",
    "                lab_s = 'SALT2'\n",
    "\n",
    "                plt.plot(wavelengths,wavelengths*10, color=cs, label=lab_o)\n",
    "                plt.plot(wavelengths,wavelengths*10, color=csn, ls=lss, label=lab_s)\n",
    "                plt.title('z = {:.3f}, t = ({:.2f}, {:.2f}), c={:.2f}'.format(cond[0,1], cond[0,0], cond[-1,0], salt[n,2]))\n",
    "                plt.legend()\n",
    "\n",
    "        plt.ylim(0.01, 1.4)        \n",
    "#         plt.ylim(0.01, 2.0)\n",
    "\n",
    "        plt.xlim(3.25e3, 7e3)\n",
    "#         plt.yscale('log')\n",
    "        plt.xlabel('de-redshifted Wavelength')\n",
    "        plt.ylabel('Normalized Luminosity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7563,
     "status": "ok",
     "timestamp": 1573693245997,
     "user": {
      "displayName": "George Stein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAX3biVEiZE5JG4GPy_AZmqFai14u8i7ZNC-6aJLg=s64",
      "userId": "11727959715016704523"
     },
     "user_tz": 480
    },
    "id": "bBoKwqkGshOA",
    "outputId": "0b554ec2-3493-4281-92b6-6a4dc3f9623a"
   },
   "outputs": [],
   "source": [
    "# so the encoder will be conditioned to both X and c, where X=flux spectra and c=conditional paramaters [t, redshift, ...]\n",
    "# similarly, the decoder will take as input z and c, where z are the latent variables \n",
    "\n",
    "zref = 0.05\n",
    "\n",
    "nspec = cond_params.shape[0]\n",
    "nwave = len(wavelengths)\n",
    "\n",
    "salt_spectra = np.zeros((nspec, nwave))\n",
    "\n",
    "for i in range(nspec):\n",
    "    if i%100 == 0: print(i)\n",
    "    salt_spectra[i] = get_flux(wavelengths, tobs=cond_params[i,0], z=cond_params[i,1], x0=salt_params[i,0], x1=salt_params[i,1], c=salt_params[i,2]) \n",
    "#     spectra_salt1[i] = get_flux(wavelengths, tobs=cond_params[i,0]*(1 + cond_params[i,1]), z=cond_params[i,1], x0=salt_params[i,0], x1=salt_params[i,1], c=salt_params[i,2]) \n",
    "#     spectra_salt2[i] = get_flux(wavelengths, tobs=cond_params[i,0]/(1 + cond_params[i,1]), z=cond_params[i,1], x0=salt_params[i,0], x1=salt_params[i,1], c=salt_params[i,2]) \n",
    "\n",
    "    \n",
    "np.savez('../data/sn_spectra_arrays_wsigma_andSALT_new.npz', \n",
    "         wavelengths       = wavelengths,\n",
    "         spectra           = sn_spectra, \n",
    "         spectra_salt      = salt_spectra,\n",
    "         spectra_sigma     = sigma_spectra,\n",
    "         spectra_IDs       = IDs,\n",
    "         cond_params       = cond_params,\n",
    "         cond_params_label = cond_params_label,\n",
    "         salt_params       = salt_params,\n",
    "         salt_params_label = salt_params_label  \n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "rms = np.sqrt(np.mean((sn_spectra-spectra_salt0 )**2, axis=0))\n",
    "plt.plot(rms)\n",
    "\n",
    "# rms = np.sqrt(np.mean((sn_spectra-spectra_salt0 / (1+cond_params[i,1]) )**2, axis=0))\n",
    "# plt.plot(rms)\n",
    "# rms = np.sqrt(np.mean((sn_spectra-spectra_salt0 / (1+zref) )**2, axis=0))\n",
    "# plt.plot(rms)\n",
    "\n",
    "# rms = np.sqrt\n",
    "\n",
    "# rms = np.sqrt(np.mean((sn_spectra-spectra_salt0 * ((1+cond_params[i,1])/(1+zref)) )**2, axis=0))\n",
    "# plt.plot(rms)\n",
    "# rms = np.sqrt(np.mean((sn_spectra-spectra_salt0 / ((1+cond_params[i,1])/(1+zref)) )**2, axis=0))\n",
    "# plt.plot(rms)\n",
    "\n",
    "rms = np.sqrt(np.mean((sn_spectra-spectra_salt1)**2, axis=0))\n",
    "plt.plot(rms)\n",
    "\n",
    "rms = np.sqrt(np.mean((sn_spectra-spectra_salt2)**2, axis=0))\n",
    "plt.plot(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETTER NETWORK AND FULL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape SN by ids, and 0 pad to (n_sn, n_timemax, n_wavelength)\n",
    "# where n_timemax is the maximum number of observations of any SN in dataset\n",
    "\n",
    "\n",
    "# n_timestep = 20\n",
    "n_timestep   = np.max(np.bincount(spectra_IDs))\n",
    "n_sn         = len(np.unique(spectra_IDs))\n",
    "n_wavelength = len(wavelengths)\n",
    "print(n_sn, n_timestep, n_wavelength)\n",
    "\n",
    "sn_spectra      = np.zeros( (n_sn, n_timestep, n_wavelength), dtype=np.float32) - 1 # set missing data to -1\n",
    "sn_spectra_salt = np.zeros( (n_sn, n_timestep, n_wavelength), dtype=np.float32) - 1 # set missing data to -1\n",
    "sn_sigma        = np.ones(  (n_sn, n_timestep, n_wavelength), dtype=np.float32)\n",
    "times           = np.zeros( (n_sn, n_timestep, 1),            dtype=np.float32) - 1 # set missing data to -1\n",
    "\n",
    "salts           = np.zeros( (n_sn, salt_params.shape[1]), dtype=np.float32)\n",
    "redshifts       = np.zeros( (n_sn), dtype=np.float32)\n",
    "\n",
    "for i, idi in enumerate(np.unique(spectra_IDs)):   \n",
    "    ids   = np.where(spectra_IDs == idi)[0]\n",
    "    n_sni = min(n_timestep, len(ids))\n",
    "    \n",
    "    sn_spectra[i,:n_sni]      = spectra[ids[:n_timestep]]\n",
    "    sn_spectra_salt[i,:n_sni] = spectra_salt[ids[:n_timestep]]\n",
    "    sn_sigma[i,:n_sni]        = spectra_sigma[ids[:n_timestep]]\n",
    "\n",
    "    times[i,:n_sni]    = cond_params[ids[:n_timestep], 0, None]\n",
    "    redshifts[i]       = cond_params[ids[0], 1]\n",
    "    salts[i,:]         = salt_params[ids[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape SN by ids, and 0 pad to (n_sn, n_timemax, n_wavelength)\n",
    "# where n_timemax is the maximum number of observations of any SN in dataset\n",
    "\n",
    "\n",
    "# n_timestep = 20\n",
    "n_timestep   = np.max(np.bincount(spectra_IDs))\n",
    "n_sn         = len(np.unique(spectra_IDs))\n",
    "n_wavelength = len(wavelengths)\n",
    "print(n_sn, n_timestep, n_wavelength)\n",
    "\n",
    "sn_spectra      = np.zeros( (n_sn, n_timestep, n_wavelength), dtype=np.float32) - 1 # set missing data to -1\n",
    "sn_spectra_salt = np.zeros( (n_sn, n_timestep, n_wavelength), dtype=np.float32) - 1 # set missing data to -1\n",
    "sn_sigma        = np.ones(  (n_sn, n_timestep, n_wavelength), dtype=np.float32)\n",
    "times           = np.zeros( (n_sn, n_timestep, 1),            dtype=np.float32) - 1 # set missing data to -1\n",
    "\n",
    "salts           = np.zeros( (n_sn, salt_params.shape[1]), dtype=np.float32)\n",
    "redshifts       = np.zeros( (n_sn), dtype=np.float32)\n",
    "\n",
    "for i, idi in enumerate(np.unique(spectra_IDs)):   \n",
    "    ids   = np.where(spectra_IDs == idi)[0]\n",
    "    n_sni = min(n_timestep, len(ids))\n",
    "    \n",
    "    sn_spectra[i,:n_sni]      = spectra[ids[:n_timestep]]\n",
    "    sn_spectra_salt[i,:n_sni] = spectra_salt[ids[:n_timestep]]\n",
    "    sn_sigma[i,:n_sni]        = spectra_sigma[ids[:n_timestep]]\n",
    "\n",
    "    times[i,:n_sni]    = cond_params[ids[:n_timestep], 0, None]\n",
    "    redshifts[i]       = cond_params[ids[0], 1]\n",
    "    salts[i,:]         = salt_params[ids[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_normalization():\n",
    "    def __init__(self, times, normed=False):\n",
    "        super(time_normalization, self).__init__()\n",
    "\n",
    "#         tmin = -10\n",
    "#         tmax = 40\n",
    "        self.tmin = np.min(times)\n",
    "        self.tmax = np.max(times)\n",
    "        \n",
    "        self.minmax = self.tmax - self.tmin\n",
    "        \n",
    "        self.normed = normed\n",
    "\n",
    "    def scale(self, times):\n",
    "        \n",
    "        if self.normed:\n",
    "            times = times * self.minmax\n",
    "            self.normed = False\n",
    "\n",
    "        else:\n",
    "            times = times/self.minmax\n",
    "            self.normed = True\n",
    "            \n",
    "        return times\n",
    "\n",
    "time_normalizer = time_normalization(times)\n",
    "times = time_normalizer.scale(times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "train_frac = 0.8\n",
    "ind_split  = int(n_sn * train_frac)\n",
    "\n",
    "sn_spectra_train      = sn_spectra[:ind_split]\n",
    "sn_spectra_salt_train = sn_spectra_salt[:ind_split]\n",
    "sn_sigma_train        = sn_sigma[:ind_split]\n",
    "\n",
    "times_train     = times[:ind_split]\n",
    "salts_train     = salts[:ind_split]\n",
    "redshifts_train = redshifts[:ind_split]\n",
    "\n",
    "\n",
    "sn_spectra_test      = sn_spectra[ind_split:]\n",
    "sn_spectra_salt_test = sn_spectra_salt[ind_split:]\n",
    "sn_sigma_test        = sn_sigma[ind_split:]\n",
    "\n",
    "times_test     = times[ind_split:]\n",
    "salts_test     = salts[ind_split:]\n",
    "redshifts_test = redshifts[ind_split:]\n",
    "\n",
    "sn_spectra_train.shape, sn_spectra_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING - simplistic batch feeding for now\n",
    "import time\n",
    "def train_model(spectra, cond_param, sigma_x, spectra_test, cond_param_test, sigma_x_test, \n",
    "                model, optimizers=tf.keras.optimizers.Adam(1e-3), \n",
    "                epochs=200, test_every=100, train_noise=False, noise_scale=1.):\n",
    "    \n",
    "    training_loss_hist = np.zeros((epochs,2))\n",
    "    test_loss_hist     = np.zeros((epochs//test_every,2))\n",
    "\n",
    "    # train using only MSE los\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        training_loss_mse, training_loss_L2z, training_logpx_zc, training_logpz, training_logqz_xc = 0., 0., 0., 0., 0.\n",
    "\n",
    "        if not train_noise: \n",
    "            noise_scale=0.\n",
    "\n",
    "        training_loss_mse = compute_apply_gradients_ae(model, \n",
    "                                            spectra, \n",
    "                                            cond_param,\n",
    "                                            sigma_x,\n",
    "                                            optimizer)\n",
    "#         training_loss_mse = compute_apply_gradients_ae(model, \n",
    "#                                             spectra + noise_scale*np.random.normal(0., sigma_x).astype(dtype=np.float32), \n",
    "#                                             cond_param,\n",
    "#                                             sigma_x,\n",
    "#                                             optimizer)\n",
    "\n",
    "        # get average\n",
    "        training_loss_hist[epoch, 0]     = epoch \n",
    "        training_loss_hist[epoch, 1]     = training_loss_mse.numpy()\n",
    "\n",
    "        if (epoch + 1) % test_every == 0:\n",
    "            end_time = time.time()\n",
    "            t_epoch  = end_time-start_time\n",
    "\n",
    "            # Calculate test loss\n",
    "            test_loss_mse = compute_loss_ae(model, spectra_test, cond_param_test, sigma_x_test)\n",
    "            test_loss_hist[epoch//test_every, 0] = epoch \n",
    "            test_loss_hist[epoch//test_every, 1] = test_loss_mse.numpy()\n",
    "\n",
    "            print('epoch={:d}, time={:.3f} s, test loss={:.6f} {:.6f}'.format(epoch, end_time-start_time, training_loss_mse.numpy(), test_loss_mse.numpy()))\n",
    "\n",
    "    return training_loss_hist, test_loss_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Model Architecture and Training params and train\n",
    "\n",
    "data_dim = sn_spectra_train.shape[2]\n",
    "cond_dim = times_train.shape[-1]\n",
    "\n",
    "encode_dims = [128, 64, 32, 16, 8]\n",
    "decode_dims = encode_dims[:-1][::-1] \n",
    "\n",
    "\n",
    "latent_dims = [2] #[2,3,4,5,6,7,8]\n",
    "# latent_dims = [1] #[2,3,4,5,6,7,8]\n",
    "\n",
    "epochs     = 2500\n",
    "\n",
    "test_every = 100\n",
    "\n",
    "# learning_rate_fn = tfk.optimizers.schedules.ExponentialDecay(\n",
    "#       initial_learning_rate=1e-1,\n",
    "#       decay_steps=1000,\n",
    "#       decay_rate=0.95, staircase=True)\n",
    "# optimizer  = tf.keras.optimizers.Adam(learning_rate_fn)\n",
    "\n",
    "optimizer  = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "dropout = True\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# train_noise = True\n",
    "train_noise = False\n",
    "\n",
    "noise_scale = 1. \n",
    "\n",
    "tf.random.set_seed(13578)\n",
    "\n",
    "# Train and plot\n",
    "plt.figure(figsize=(10,6))\n",
    "for il, latent_dim in enumerate(latent_dims):\n",
    "    \n",
    "    # training function here to prevent autograph causing \n",
    "    # ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
    "\n",
    "    @tf.function\n",
    "    def compute_apply_gradients_ae(model, x, cond, sigma, optimizer):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = compute_loss_ae(model, x, cond, sigma)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "#         print('Learning rate:', optimizer._decayed_lr(tf.float32))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss_ae(model, x, cond, sigma):\n",
    "        \n",
    "        z      = model.encode(x, cond)\n",
    "        x_pred = model.decode(z, cond)\n",
    "        \n",
    "        mask = tf.not_equal(x, -1.)\n",
    "        # Reconstruction loss: E[log P(X|z)]\n",
    "#         loss_mse = tf.reduce_mean(tf.losses.mean_squared_error(x, x_pred))\n",
    "\n",
    "        loss_mse = tf.reduce_mean( tf.reduce_mean( tf.boolean_mask((x - x_pred)**2, mask), axis=-1) )\n",
    "        return loss_mse\n",
    "\n",
    "#         loss_nll =  tf.reduce_mean( tf.reduce_mean( tf.boolean_mask(tf.math.log(sigma**2)/2 + (x - x_pred)**2/(2*sigma**2), mask), axis=-1) )\n",
    "#         return loss_nll\n",
    "\n",
    "#     logpx_zc_mean = -tf.reduce_mean(logpx_zc)\n",
    "# #         loss_mse = tf.reduce_mean( (x - x_pred)**2 / sigma**2)\n",
    "#         loss_mse = tf.reduce_mean( tf.reduce_mean( (x - x_pred)**2, axis=-1))\n",
    "     \n",
    "    \n",
    "    print('number of latent dimensions = ', latent_dim)\n",
    "\n",
    "    # Create model\n",
    "    AEmodel = AE_2D(data_dim, n_timestep, latent_dim, cond_dim, encode_dims, decode_dims, dropout=dropout, dropout_rate=dropout_rate)\n",
    "\n",
    "    # Print Model Summary\n",
    "    summary=True #False\n",
    "\n",
    "    if summary and (il == 0):\n",
    "        print(\"Encoder Summary\")\n",
    "        AEmodel.encoder.summary()\n",
    "\n",
    "        print(\"Decoder Summary\")\n",
    "        AEmodel.decoder.summary()\n",
    "\n",
    "    training_loss, test_loss = train_model(sn_spectra_train, times_train, sn_sigma_train,\n",
    "                                           sn_spectra_test, times_test, sn_sigma_test,\n",
    "                                           AEmodel, optimizers=optimizer, epochs=epochs, \n",
    "                                           test_every=test_every,\n",
    "                                           train_noise=train_noise, noise_scale=noise_scale)\n",
    "\n",
    "\n",
    "    plt.semilogy(training_loss[:,0], training_loss[:,1], ls='-', c='C0', label='MSE')\n",
    "    plt.semilogy(test_loss[:,0], test_loss[:,1], ls='--', c='C0')#, label='MSE')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "# AEmodel.training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trainable_variables = 0\n",
    "for weights in AEmodel.decoder.trainable_variables:\n",
    "    n_trainable_variables = n_trainable_variables + np.prod(weights.shape)\n",
    "print(n_trainable_variables)\n",
    "\n",
    "# plot negative log loss \n",
    "def NLL(model, x, cond, sigma):\n",
    "        \n",
    "    z      = model.encode(x, cond)\n",
    "    x_pred = model.decode(z, cond)\n",
    "\n",
    "    return tf.math.log(sigma**2)/2,  (x - x_pred)**2/(2*sigma**2), (x - x_pred)**2\n",
    "\n",
    "        \n",
    "nll0, nll1, mse = NLL(AEmodel, sn_spectra_train, times_train, sn_sigma_train)\n",
    "for i in range(3):\n",
    "    plt.figure()\n",
    "    plt.semilogy((nll0.numpy() + nll1.numpy())[i].T, '-')\n",
    "    plt.semilogy(nll0.numpy()[i].T, '--')\n",
    "    plt.semilogy(nll1.numpy()[i].T, ':')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.figure()\n",
    "    plt.semilogy(mse.numpy()[i].T, '-')\n",
    "\n",
    "    nll0, nll1, mse = NLL(AEmodel, sn_spectra_test, times_test, sn_sigma_test)\n",
    "for i in range(3):\n",
    "    plt.figure()\n",
    "    plt.semilogy((nll0.numpy() + nll1.numpy())[i].T, '-')\n",
    "    plt.semilogy(nll0.numpy()[i].T, '--')\n",
    "    plt.semilogy(nll1.numpy()[i].T, ':')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.figure()\n",
    "    plt.semilogy(mse.numpy()[i].T, '-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "nplt = 5\n",
    "\n",
    "def plt_predictions(wavelengths, x_true, x_pred, sigma, red, z_lat, title='Training'):\n",
    "    z_lat = z_lat.numpy()\n",
    "    dm = x_true[:,0] != -1.\n",
    "    \n",
    "    x_truei = x_true[dm].copy()\n",
    "    x_predi = x_pred[dm].copy()\n",
    "    sigmai  =  sigma[dm].copy()\n",
    "\n",
    "    cmap = cm.coolwarm\n",
    "    colors = cmap(np.linspace(0,1,len(x_truei)))\n",
    "\n",
    "    fig, ((ax1, ax2)) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(16,8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(1.5)\n",
    "        ax2.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "    ax1.tick_params('both', length=6, width=1.5, which='major', color='k',direction='in')                                         \n",
    "    ax1.tick_params('both', length=3, width=1.5, which='minor', color='k',direction='in')\n",
    "    ax2.tick_params('both', length=6, width=1.5, which='major', color='k',direction='in')                                         \n",
    "    ax2.tick_params('both', length=3, width=1.5, which='minor', color='k',direction='in')\n",
    "\n",
    "    for i in range(x_truei.shape[0]):\n",
    "        ax1.plot(wavelengths, x_truei[i], '-', c='k', lw=2)#colors[i])\n",
    "        ax1.plot(wavelengths, x_predi[i], '-', c=colors[i], lw=2)\n",
    "\n",
    "        ax2.plot(wavelengths, np.abs(x_predi[i]-x_truei[i])/sigmai[i], '--', c=colors[i])\n",
    "#         ax2.set_ylim(0.1,2.0)\n",
    "    print(red, z_lat)\n",
    "    ax1.set_title(title+' spectra and AE reconstructions, z={:.4f}, latent=[{:.2f}, {:.2f}]'.format(red, z_lat[0], z_lat[1]))\n",
    "    ax1.set_ylabel('Restframe Flux')\n",
    "    ax2.set_ylabel('$|x-x_{recon}|/\\sigma$')\n",
    "    ax2.set_xlabel('Wavelength [$\\AA$]')\n",
    "\n",
    "    ax2.set_yscale('log')\n",
    "    plt.subplots_adjust(hspace=0.025)\n",
    "\n",
    "z = AEmodel.encoder((sn_spectra_train, times_train))\n",
    "sn_spectra_recon = AEmodel.decoder((z, times_train)).numpy()\n",
    "\n",
    "for i in range(nplt):  \n",
    "    plt_predictions(wavelengths, sn_spectra_train[i], sn_spectra_recon[i], sn_sigma[i], redshifts_train[i], z[i])\n",
    "    plt_predictions(wavelengths, sn_spectra_train[i], sn_spectra_salt[i], sn_sigma[i],  redshifts_train[i], z[i], title='SALT2')\n",
    "\n",
    "    \n",
    "z = AEmodel.encoder((sn_spectra_test, times_test))\n",
    "sn_spectra_recon = AEmodel.decoder((z, times_test)).numpy()\n",
    "\n",
    "for i in range(nplt):\n",
    "    \n",
    "    plt_predictions(wavelengths, sn_spectra_test[i], sn_spectra_recon[i], sn_sigma_test[i], redshifts_test[i], z[i], title='Testing')\n",
    "    plt_predictions(wavelengths, sn_spectra_train[i], sn_spectra_salt[i], sn_sigma[i], redshifts_test[i], z[i], title='SALT2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "z_train = AEmodel.encoder((sn_spectra_train, times_train))\n",
    "z_test  = AEmodel.encoder((sn_spectra_test, times_test))\n",
    "\n",
    "print(z_train.shape, redshifts_train.shape, salts_train.shape)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "nplt = 10\n",
    "d = {}\n",
    "for i in range(z_train.shape[1]):    \n",
    "    d['$z_{:d}$'.format(i)] = z_train[:,i]\n",
    "for i in range(salts_train.shape[1]):\n",
    "    d[salt_params_label[i]] = salts_train[:,i]   \n",
    "    \n",
    "d['redshift'] = redshifts_train\n",
    "d['SN ID'] = np.arange(z.shape[0])\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "sns.pairplot(df, corner=True)#, hue='SN ID')\n",
    "\n",
    "\n",
    "# # Train\n",
    "# z = AEmodel.encoder((spectra_test, times_test))\n",
    "# spectra_pred = AEmodel.decoder((z, times_test)).numpy()\n",
    "# print(z.shape, spectra_test.shape)\n",
    "\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# nplt = 10\n",
    "# d = {}\n",
    "# for i in range(z.shape[1]):    \n",
    "#     d['$z_{:d}$'.format(i)] = z[:,i]\n",
    "# for i in range(redshifts_test.shape[1]):\n",
    "#     d['redshift'] = redshifts_test[:,i]\n",
    "# for i in range(salts_test.shape[1]):\n",
    "#     d[salt_params_label[i+1]] = salts_test[:,i]    \n",
    "\n",
    "# d['SN ID'] = np.arange(z.shape[0])\n",
    "\n",
    "# df = pd.DataFrame(data=d)\n",
    "# sns.pairplot(df, corner=True)#, hue='SN ID')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SN_trials.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
