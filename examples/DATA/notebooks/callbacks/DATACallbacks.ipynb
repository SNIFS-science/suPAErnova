{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33feec2-dc8a-48db-896f-ea00d4a752da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import suPAErnova as snpae\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Some useful paths to have access to\n",
    "cwd = Path.cwd()\n",
    "examples_dir = cwd.parent.parent.parent\n",
    "data_dir = examples_dir / \"suPAErnova_data\" # Put your data into this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e901be-45c1-432f-a665-9abc50f0e0f5",
   "metadata": {},
   "source": [
    "# Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5991d-f7ea-461d-bfc1-da3019afcba4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = False # Increase log verbosity\n",
    "force = False # Rerun all steps every time\n",
    "\n",
    "cfg = snpae.setup_global_config({}, verbose=verbose, force=force) # Just pass an empty dictionary to initialise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93146e-4e0d-43a7-b53b-674f5ac7bd68",
   "metadata": {},
   "source": [
    "# Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6503e-3b48-4cac-857f-ae87a1938e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that these keys *MUST* be captilalised. This is not the case when using a `suPAErnova.toml` config file.\n",
    "data_cfg = {\n",
    "    # === Required Keys ===\n",
    "\n",
    "    # Path to directory containing data.\n",
    "    #   Can be absolute or relative to the base path.\n",
    "    \"DATA_DIR\": str(data_dir), # Needs to be a string so that SuPAErnova can validate it\n",
    "    \n",
    "    # Metadata CSV containing SN names and SALT fit parameters.\n",
    "    #   Can be absolute or relative to the data path.\n",
    "    \"META\": \"meta.csv\",\n",
    "\n",
    "    # TXT file containing additional SALT fit parameters.\n",
    "    #   Can be absolute or relative to the data path.\n",
    "    \"IDR\": \"IDR_eTmax.txt\",\n",
    "\n",
    "    # TXT file containing a mask of bad spectra / wavelength ranges.\n",
    "    #   Can be absolute or relative to the data path.\n",
    "    \"MASK\": \"mask_info_wmin_wmax.txt\",\n",
    "\n",
    "    # === Optional Keys ===\n",
    "\n",
    "    # Which assumed cosmology to use when running SALT models.\n",
    "    #   Available cosmological can be found [here](https://docs.astropy.org/en/stable/cosmology/realizations.html)\n",
    "    #   Defaults to WMAP7\n",
    "    \"COSMOLOGICAL_MODEL\": \"WMAP7\",\n",
    "\n",
    "    # The absolute path to an existing SALT2/3 model, or the name of an existing SNCosmo SALT2/3 model.\n",
    "    #   Defaults to salt3\n",
    "    \"SALT_MODEL\": \"salt3\",\n",
    "\n",
    "    # Minimum phase for spectral data, relative to peak. Spectral data earlier than this phase will be cut.\n",
    "    #   Defaults to -10.0\n",
    "    \"MIN_PHASE\": -10,\n",
    "\n",
    "    # Maximum phase for spectral data, relative to peak. Spectral data later than this phase will be cut.\n",
    "    #   Defaults to 40.0\n",
    "    \"MAX_PHASE\": 40,\n",
    "\n",
    "    # The fraction of data to be used for training, with the rest of the data going to testing and validation.\n",
    "    #   Defaults to 0.75\n",
    "    \"TRAIN_FRAC\": 0.75,\n",
    "\n",
    "    # The seed used throughout data preperation, in particular for randomly splitting the data into training, testing, and validation bins.\n",
    "    #   Defaults to 12345\n",
    "    \"SEED\": 12345,\n",
    "\n",
    "    # === Analysis Keys ===\n",
    "    \"ANALYSIS\": {\n",
    "        # Which spectra to plot\n",
    "        #    str: The name of a single spectrum to plot\n",
    "        #    list[str]: Names of each spectrum to plot\n",
    "        #    True: Plot every spectrum\n",
    "        \"PLOT_SPECTRA\": \"CSS110918_01\"\n",
    "    }\n",
    "}\n",
    "\n",
    "cfg[\"DATA\"] = data_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721b543-c1a0-4147-b2ab-c0ad9b3907d2",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "The easiest way to interact with the `SuPAErnova` pipeline, without having to delve into the source code, is through callback functions. These are user-defined functions which run before and after different stages within each step. When using a `suPAErnova.toml` file, these callback function are defined in scripts, with the path to these scripts provided in the confg file. Here you can directly define your functions and pass them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6964c2-3e51-4a80-9c48-240629598752",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = {}\n",
    "\n",
    "# analyse\n",
    "def pre_analyse(self) -> None:\n",
    "    print(\"pre-analyse callback\")\n",
    "\n",
    "def post_analyse(self) -> None:\n",
    "    print(\"post-analyse callback\")\n",
    "\n",
    "callbacks[\"ANALYSE\"] = {\"PRE\": pre_analyse, \"POST\": post_analyse}\n",
    "\n",
    "# calculate_laser_line_mask\n",
    "def pre_calculate_laser_line_mask(self) -> None:\n",
    "    print(\"pre-calculate_laser_line_mask callback\")\n",
    "\n",
    "def post_calculate_laser_line_mask(self) -> None:\n",
    "    print(\"post-calculate_laser_line_mask callback\")\n",
    "\n",
    "callbacks[\"CALCULATE_LASER_LINE_MASK\"] = {\"PRE\": pre_calculate_laser_line_mask, \"POST\": post_calculate_laser_line_mask}\n",
    "\n",
    "# calculate_salt_flux\n",
    "def pre_calculate_salt_flux(self) -> None:\n",
    "    print(\"pre-calculate_salt_flux callback\")\n",
    "\n",
    "def post_calculate_salt_flux(self) -> None:\n",
    "    print(\"post-calculate_salt_flux callback\")\n",
    "\n",
    "callbacks[\"CALCULATE_SALT_FLUX\"] = {\"PRE\": pre_calculate_salt_flux, \"POST\": post_calculate_salt_flux}\n",
    "\n",
    "# calculate_wavelength_mask\n",
    "def pre_calculate_wavelength_mask(self) -> None:\n",
    "    print(\"pre-calculate_wavelenth_mask callback\")\n",
    "\n",
    "def post_calculate_wavelength_mask(self) -> None:\n",
    "    print(\"post-calculate_wavelength_mask callback\")\n",
    "\n",
    "callbacks[\"CALCULATE_WAVELENGTH_MASK\"] = {\"PRE\": pre_calculate_wavelength_mask, \"POST\": post_calculate_wavelength_mask}\n",
    "\n",
    "# finalise_data\n",
    "def pre_finalise_data(self) -> None:\n",
    "    print(\"pre-finalise_data callback\")\n",
    "\n",
    "def post_finalise_data(self) -> None:\n",
    "    print(\"post-finalise_data callback\")\n",
    "\n",
    "callbacks[\"FINALISE_DATA\"] = {\"PRE\": pre_finalise_data, \"POST\": post_finalise_data}\n",
    "\n",
    "# get_dims\n",
    "def pre_get_dims(self) -> None:\n",
    "    print(\"pre-get_dims callback\")\n",
    "\n",
    "def post_get_dims(self) -> None:\n",
    "    print(\"post-get_dims\")\n",
    "\n",
    "callbacks[\"GET_DIMS\"] = {\"PRE\": pre_get_dims, \"POST\": post_get_dims}\n",
    "\n",
    "# load_data\n",
    "def pre_load_data(self) -> None:\n",
    "    print(\"pre-load_data callback\")\n",
    "\n",
    "def post_load_data(self) -> None:\n",
    "    print(\"post-load_data callback\")\n",
    "\n",
    "callbacks[\"LOAD_DATA\"] = {\"PRE\": pre_load_data, \"POST\": post_load_data}\n",
    "\n",
    "# result\n",
    "def pre_result(self) -> None:\n",
    "    print(\"pre-result callback\")\n",
    "\n",
    "def post_result(self) -> None:\n",
    "    print(\"post-result callback\")\n",
    "\n",
    "callbacks[\"RESULT\"] = {\"PRE\": pre_result, \"POST\": post_result}\n",
    "\n",
    "# run\n",
    "def pre_run(self) -> None:\n",
    "    print(\"pre-run callback\")\n",
    "\n",
    "def post_run(self) -> None:\n",
    "    print(\"post-run callback\")\n",
    "\n",
    "callbacks[\"RUN\"] = {\"PRE\": pre_run, \"POST\": post_run}\n",
    "\n",
    "# setup\n",
    "def pre_setup(self) -> None:\n",
    "    print(\"pre-setup callback\")\n",
    "\n",
    "def post_setup(self) -> None:\n",
    "    print(\"post-setup callback\")\n",
    "\n",
    "callbacks[\"SETUP\"] = {\"PRE\": pre_setup, \"POST\": post_setup}\n",
    "\n",
    "# split_train_test\n",
    "def pre_split_train_test(self) -> None:\n",
    "    print(\"pre-split_train_test callback\")\n",
    "\n",
    "def post_split_train_test(self) -> None:\n",
    "    print(\"post-split_train_test callback\")\n",
    "\n",
    "callbacks[\"SPLIT_TRAIN_TEST\"] = {\"PRE\": pre_split_train_test, \"POST\": post_split_train_test}\n",
    "\n",
    "# transform_data\n",
    "def pre_transform_data(self) -> None:\n",
    "    print(\"pre-transform_data callback\")\n",
    "\n",
    "def post_transform_data(self) -> None:\n",
    "    print(\"post-transform_data callback\")\n",
    "\n",
    "callbacks[\"TRANSFORM_DATA\"] = {\"PRE\": pre_transform_data, \"POST\": post_transform_data}\n",
    "\n",
    "# validate\n",
    "def pre_validate(self) -> None:\n",
    "    print(\"pre-validate callback\")\n",
    "\n",
    "def post_validate(self) -> None:\n",
    "    print(\"post-validate callback\")\n",
    "\n",
    "callbacks[\"VALIDATE\"] = {\"PRE\": pre_validate, \"POST\": post_validate}\n",
    "\n",
    "\n",
    "cfg[\"DATA\"][\"CALLBACKS\"] = callbacks\n",
    "\n",
    "data = snpae.steps.DATAStep(cfg)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dadb65-da07-4c61-ac99-bed28641d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, result = data.setup()\n",
    "if not success: # Make sure you handle failures appropriately!\n",
    "    data.log.error(f\"Error running setup: {result}\")\n",
    "success, result = data.run()\n",
    "if not success: # Make sure you handle failures appropriately!\n",
    "    data.log.error(f\"Error running: {result}\")\n",
    "success, result = data.result()\n",
    "if not success: # Make sure you handle failures appropriately!\n",
    "    data.log.error(f\"Error saving results: {result}\")\n",
    "success, result = data.analyse()\n",
    "if not success: # Make sure you handle failures appropriately!\n",
    "    data.log.error(f\"Error analysing: {result}\")\n",
    "img = mpimg.imread(data.plotpath / \"CSS110918_01.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
